{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This script will take the input file and clean the data to remove https links, # and \\r and non-english comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time  \n",
    "import ast\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, json\n",
    "from polyglot.detect import Detector \n",
    "import cld2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the training data from the csv file\n",
    "header = ['label','comment','parent_comment']\n",
    "data = pd.read_table('train-balanced.csv',\n",
    "                    sep='\\t', \n",
    "                    names=header,\n",
    "                    usecols=[0,1,9],\n",
    "                    dtype={'label':int,'comment':str,'parent_comment':str},\n",
    "                    keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the test data from the csv file\n",
    "header = ['label','comment', 'parent_comment']\n",
    "test_data = pd.read_table('test-balanced.csv',\n",
    "                    sep='\\t', \n",
    "                    names=header,\n",
    "                    usecols=[0,1,9],\n",
    "                    dtype={'label':int,'comment':str},\n",
    "                    keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape :  (251608, 3)\n",
      "Train data shape :  (1010826, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test data shape : \", test_data.shape)\n",
    "print(\"Train data shape : \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the slang dictionary that is already created\n",
    "f = open(\"Slangdictionary.txt\",\"r\")\n",
    "res1=f.read()\n",
    "f.close()\n",
    "slangdict = ast.literal_eval(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to clean the comments\n",
    "def comment_clean(user_comment):\n",
    "    # remove trailing \\r and \\n    \n",
    "    user_comment.rstrip('\\r\\n')\n",
    "    \n",
    "    #remove the # from hashtag\n",
    "    if '#' in user_comment:\n",
    "        hash_tag = re.search('#',user_comment)\n",
    "        if hash_tag is not None:\n",
    "            user_comment = user_comment.replace(hash_tag.group(0),' ')\n",
    "    #remove the redit tags(r/) from comment\n",
    "    if 'r/' in user_comment:\n",
    "        r_tag = re.search('r/',user_comment)\n",
    "        if r_tag is not None:\n",
    "            user_comment = user_comment.replace(r_tag.group(0),' ')\n",
    "    #remove the URL links from comments  \n",
    "    if 'HTTP' in user_comment:\n",
    "        # url of the form [link name](http://url)\n",
    "        url_link = re.search('\\[(.*)\\(HTTP(.*)\\)', user_comment)\n",
    "        if url_link is not None:\n",
    "            user_comment = user_comment.replace(url_link.group(0),' ')\n",
    "    if 'http' in user_comment:\n",
    "        # url of the form [link name](http://url)\n",
    "        url_link = re.search('\\[(.*)\\(http(.*)\\)', user_comment)\n",
    "        if url_link is not None:\n",
    "            user_comment = user_comment.replace(url_link.group(0),' ')\n",
    "        else:\n",
    "            #url of the form http:/\n",
    "            url_link = re.search('http(.*)', user_comment)\n",
    "            if url_link is not None:\n",
    "                user_comment = user_comment.replace(url_link.group(0),' ')                \n",
    "      \n",
    "    \n",
    "    # Check if the comment has exactly 2 stars\n",
    "    if user_comment.count('*')==2:\n",
    "        boldwords = re.search(r\"\\*(.*?)\\*\",user_comment)\n",
    "        #print(boldwords.group(0))\n",
    "        # Check if the comments have any other text other than **\n",
    "        if boldwords.group(0) != \"**\":\n",
    "            Wordstocapitalize = re.findall(r\"\\*(.*?)\\*\",boldwords.group(0))\n",
    "            Wordstocapitalize = \"\".join( Wordstocapitalize)\n",
    "            # Replace the user comment with capitalized words\n",
    "            user_comment = user_comment.replace(boldwords.group(0),Wordstocapitalize.upper())\n",
    "    # replace the slangs\n",
    "    comment_words = re.sub(r\"[^a-zA-Z0-9\\s\\']\",\"\",user_comment)         \n",
    "    comment_words=comment_words.split()\n",
    "    for word in comment_words:\n",
    "        if word.upper() in slangdict.keys():\n",
    "            user_comment = user_comment.replace(word.upper(),slangdict[word.upper()])\n",
    "        elif word in slangdict.keys():\n",
    "            user_comment = user_comment.replace(word,slangdict[word]) \n",
    "        \n",
    "    # remove numbers from comments to pass it through the langauge detector\n",
    "    user_comment_not_num = re.sub(r'\\d+', '', user_comment) \n",
    "    \n",
    "    # replace non english comments with empty string\n",
    "    try:\n",
    "        isReliable, textBytesFound, details = cld2.detect(user_comment_not_num)\n",
    "    except:\n",
    "        try_text = ''.join(x for x in user_comment_not_num if x.isprintable())\n",
    "        isReliable, textBytesFound, details = cld2.detect(try_text)\n",
    "    cld_match = details[0][0]\n",
    "    if not (cld_match == 'ENGLISH'):\n",
    "        poly_match = Detector(user_comment_not_num, quiet=True).language.name\n",
    "        if (poly_match != 'English'):\n",
    "            user_comment = ' '               \n",
    "    return user_comment           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean each comment and parent comment \n",
    "data[['comment','parent_comment']] = data[['comment','parent_comment']].applymap(comment_clean)\n",
    "# remove data with empty comments\n",
    "valid_comment = data['comment'] != ' '\n",
    "data = data[valid_comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the cleaned train data into a csv file\n",
    "data.to_csv('clean_data_train_balanced.csv',\n",
    "           sep= '|',\n",
    "           index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the test data\n",
    "test_data[['comment','parent_comment']] = test_data[['comment','parent_comment']].applymap(comment_clean)\n",
    "# remove data with empty comments\n",
    "valid_comment = test_data['comment'] != ' '\n",
    "test_data = test_data[valid_comment]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning Test data shape :  (243784, 3)\n",
      "After cleaning Train data shape :  (978934, 3)\n"
     ]
    }
   ],
   "source": [
    "# shape of data frames after cleaning\n",
    "print(\"After cleaning Test data shape : \", test_data.shape)\n",
    "print(\"After cleaning Train data shape : \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the cleaned test data into a csv file\n",
    "test_data.to_csv('clean_data_test_balanced_Wparent.csv',\n",
    "           sep= '|',\n",
    "           index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
